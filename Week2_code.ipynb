{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 2 CODE\n",
    "\n",
    "### Content:\n",
    "* TASK 1 (a) - Multiresolution histogram for only one level.\n",
    "* TASK 2 (a) - Evaluation of TASK 1 (a).\n",
    "* TASK 1 (b) - Multiresolution histogram concatenating many levels.\n",
    "* TASK 2 (b) - Evaluation of TASK 1 (b).\n",
    "* TASK 3\n",
    "* TASK 4\n",
    "* TASK 5\n",
    "* TASK 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial import distance\n",
    "import ml_metrics as metrics\n",
    "import pickle\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK1 (a) - Multiresolution histogram for only one level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogrames de les imatges de \"bbdd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberBins = 256\n",
    "Level = 10 #Divisions per axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing image...   ./bbdd/bbdd_00278.jpg"
     ]
    }
   ],
   "source": [
    "imagesFolder = \"./bbdd/\"\n",
    "histogram_bbdd_matrix = np.empty([0, numberBins*3*Level**2]) #Creem una matriu buida\n",
    "#print(histogram_bbdd_matrix.shape)\n",
    "\n",
    "def blockbasedHistogram_oneLevel(img,level):\n",
    "    #Calculem tamany del block\n",
    "    height, width = img.shape[:2]\n",
    "    block_height = int(height/level)\n",
    "    block_width = int(width/level)\n",
    "    hist_img = np.empty([0,0])\n",
    "    colorx = ('x','y','z')\n",
    "    canal = 0\n",
    "    for i,col in enumerate(colorx): #Bucle per recorrer els canals de cada imatge  \n",
    "        for r in range(level): #Bucle per recorrer els blocs d'una mateixa row\n",
    "            for c in range(level): #Bucle per recorrer els blocs d'una mateixa column\n",
    "                \n",
    "                block = img[r*block_height:r*block_height+block_height, c*block_width:c*block_width+block_width] \n",
    "                hist = cv2.calcHist([block],[i],None,[numberBins],[0,256]) #Calculem histogrames per blocs\n",
    "                hist_t = hist.transpose()      \n",
    "                #print(hist_t.shape)\n",
    "                #print(hist_img.shape)\n",
    "                if (i==0) and (r==0) and (c==0):\n",
    "                    hist_img = hist_t\n",
    "                else:\n",
    "                    hist_img = np.concatenate((hist_img, hist_t), axis = 1)\n",
    "\n",
    "    cv2.normalize(hist_img, hist_img, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    return hist_img\n",
    "    \n",
    "for filename in sorted(listdir(imagesFolder)): #Bucle per recorrer les imatges de la bbdd\n",
    "    if(filename != '.DS_Store'):\n",
    "        #print(imagesFolder + filename)\n",
    "        print (\"\\r Processing image...   {}\".format(imagesFolder+filename), end=\"\")\n",
    "        img = cv2.imread(imagesFolder + filename)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2Lab)\n",
    "        hist_img = blockbasedHistogram_oneLevel(img,Level)\n",
    "        histogram_bbdd_matrix = np.vstack((histogram_bbdd_matrix, hist_img))   \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279, 76800)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histogram_bbdd_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogrames de les imatges de QSD2_W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing image...   ./qsd2_w1/00029.jpg"
     ]
    }
   ],
   "source": [
    "query2folder = './qsd2_w1/'\n",
    "histogram_query2_matrix = np.empty([0, numberBins*3*Level**2])\n",
    "\n",
    "\n",
    "def mask_generator(query_img):\n",
    "\n",
    "    #************************************************************************************************    \n",
    "\n",
    "    # MASK GENERATOR\n",
    "    #************************************************************************************************\n",
    "    \n",
    "    gray = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "    # noise removal\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening,kernel,iterations=3) #Fals. El sure \n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,3)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.15*dist_transform.max(),255,0) #0.15 26.57% \n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    markers[markers != 0] = 200\n",
    "\n",
    "    #35\n",
    "    markers[0:77,:] = 100\n",
    "    sure_fg[0:77,:] = 100\n",
    "    markers[len(markers)-78:len(markers)-1,:] = 100\n",
    "    sure_fg[len(markers)-78:len(markers)-1,:] = 100\n",
    "    markers[:,0:77] = 100\n",
    "    sure_fg[:,0:77] = 100\n",
    "    markers[:,len(markers[0,:])-78:len(markers[0,:])-1] = 100\n",
    "    sure_fg[:,len(markers[0,:])-78:len(markers[0,:])-1] = 100\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[sure_fg == 0] = 0\n",
    "\n",
    "    markersres = cv2.watershed(query_img,markers)\n",
    "\n",
    "    markersres[markersres == 201] = 255\n",
    "    markersres[markersres == 101] = 0\n",
    "    markersres[markersres == -1] = 255\n",
    "\n",
    "    #Make the mask binary\n",
    "    markersres = markersres/np.max(markersres)\n",
    "\n",
    "    #print(markersres.dtype)\n",
    "    mask = markersres.astype('uint8') \n",
    "\n",
    "    #opening (dilation + erosion) per eliminar pixels que son 1 a les cantonades de la mascara\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    mask = cv2.morphologyEx(mask,cv2.MORPH_OPEN,kernel)\n",
    "    \n",
    "    return mask\n",
    "    \n",
    "def blockbasedHistogram_oneLevel_maskRemoval(query_img, mask, level):\n",
    "    \n",
    "    #Compute the histogram\n",
    "    query_img = cv2.cvtColor(query_img,cv2.COLOR_BGR2Lab)\n",
    "    \n",
    "    #************************************************************************************************    \n",
    "\n",
    "    # CROP IMAGE\n",
    "    #************************************************************************************************\n",
    "\n",
    "    # Mask of non-black pixels (assuming image has a single channel).\n",
    "    mask_rows, mask_columns = mask.shape\n",
    "    mask_crop = mask > 0\n",
    "\n",
    "    # Coordinates of non-black pixels.\n",
    "    coords = np.argwhere(mask_crop)\n",
    "\n",
    "    # Bounding box of non-black pixels.\n",
    "    x0, y0 = coords.min(axis=0)\n",
    "    x1, y1 = coords.max(axis=0) + 1   # slices are exclusive at the top\n",
    "\n",
    "    # Get the contents of the bounding box.\n",
    "    cropped = query_img[x0:x1, y0:y1]\n",
    "    mask_cropped = mask[x0:x1, y0:y1]\n",
    "\n",
    "   \n",
    "    #************************************************************************************************    \n",
    "\n",
    "\n",
    "    #Compute block size\n",
    "    height, width = cropped.shape[:2]\n",
    "    block_height = int(height/level)\n",
    "    block_width = int(width/level)\n",
    "    hist_img = np.empty([0,0])\n",
    "    \n",
    "    color = ('b','g','r')\n",
    "    \n",
    "    for i,col in enumerate(color):\n",
    "        #Loop over blocks for each row\n",
    "        for r in range(level):\n",
    "            #Loop over blocks for each column\n",
    "            for c in range(level):\n",
    "                #print(\"canal: \", i)\n",
    "                #print(\"r    : \", r)\n",
    "                #print(\"c    : \", c)\n",
    "                block = cropped[r*block_height:r*block_height+block_height, c*block_width:c*block_width+block_width] \n",
    "                mask_block = mask_cropped[r*block_height:r*block_height+block_height, c*block_width:c*block_width+block_width]\n",
    "                hist = cv2.calcHist([block],[i],mask_block,[numberBins],[0,256]) #Calculem histogrames per blocs\n",
    "                hist_t = hist.transpose()  \n",
    "                #print(hist_t.shape)\n",
    "                #print(hist_img.shape)\n",
    "                if (i==0) and (r==0) and (c==0):\n",
    "                    hist_query = hist_t\n",
    "                    #print(hist_query.shape)\n",
    "                else:\n",
    "                    hist_query = np.concatenate((hist_query,hist_t), axis = 1)\n",
    "                    #print(hist_query.shape)\n",
    "\n",
    "    #print(histogram_query2_matrix.shape)\n",
    "    #print(hist_query.shape)\n",
    "    cv2.normalize(hist_query, hist_query, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    return hist_query\n",
    "\n",
    "\n",
    "for filename in sorted(listdir(query2folder)):\n",
    "    if(filename != '.DS_Store' and (filename.split('.')[1] == 'jpg')):\n",
    "        \n",
    "        print (\"\\r Processing image...   {}\".format(query2folder+filename), end=\"\")\n",
    "        query_img = cv2.imread(query2folder + filename)\n",
    "        \n",
    "        # Mask genetation\n",
    "        mask = mask_generator(query_img)\n",
    "        \n",
    "        #Save to the histogram_query matrix\n",
    "        hist_query = blockbasedHistogram_oneLevel_maskRemoval(query_img, mask, Level)\n",
    "        histogram_query2_matrix = np.vstack((histogram_query2_matrix, hist_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 76800)\n"
     ]
    }
   ],
   "source": [
    "print(histogram_query2_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2 (a) - Evaluation of TASK 1 (a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the functions used to evaluate Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeMatrixRetrieval(histogram_bbdd, histogram_query, K=10):\n",
    "    dst = np.zeros((30, 279))\n",
    "    matrix_retrieval = np.zeros((30,K))\n",
    "\n",
    "    for query_image_index in range(0,len(histogram_query)): \n",
    "        for bbdd_image_index in range(0, len(histogram_bbdd)):\n",
    "\n",
    "            dst[query_image_index,bbdd_image_index] = distance.braycurtis(histogram_query[query_image_index,:], histogram_bbdd[bbdd_image_index,:])\n",
    "\n",
    "        matrix_retrieval[query_image_index,:] = np.argsort(dst[query_image_index,:])[:K]\n",
    "        \n",
    "    #Convertir idx a list of lists\n",
    "    matrix_retrieval = matrix_retrieval.astype(int)\n",
    "    matrix_retrieval_lst = matrix_retrieval.tolist()\n",
    "    return matrix_retrieval_lst\n",
    "\n",
    "def evaluationTask1(matrix_retrieval, K=10):  \n",
    "    #LLEGIR GT\n",
    "    with open(query2folder + 'gt_corresps.pkl', 'rb') as fd:\n",
    "            ll = pickle.load(fd)\n",
    "            #print(ll)\n",
    "    gt = np.empty((0,0))\n",
    "\n",
    "    ll_prp = np.zeros((len(ll),1))\n",
    "\n",
    "    for i in range(0,len(ll)):\n",
    "        ll_prp[i] = ll[i][0]\n",
    "\n",
    "    ll_prp_lst = ll_prp.tolist()\n",
    "\n",
    "    mapak = metrics.average_precision.mapk(ll_prp_lst, matrix_retrieval, k=K)    \n",
    "    score = mapak*100\n",
    "    #print(\"SCORE: \",score, \"%\")\n",
    "\n",
    "    #GUARDAR PICKLE RESULT\n",
    "    pickle_out = open(\"result_qsd2.pkl\", \"wb\")\n",
    "    pickle.dump(matrix_retrieval, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.66666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=10\n",
    "matrix_retrieval = computeMatrixRetrieval(histogram_bbdd_matrix, histogram_query2_matrix, K)\n",
    "evaluationTask1(matrix_retrieval, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1 (b) - Multiresolution histogram concatenating many levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogrames de les imatges de \"bbdd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberBins = 256\n",
    "LevelMax = 5 #Divisions per axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing image...   ./bbdd/bbdd_00278.jpg"
     ]
    }
   ],
   "source": [
    "imagesFolder = \"./bbdd/\"\n",
    "\n",
    "numeroDeBlocs = 0; #Variable per saber quants histogrames de blocs es calcularan i aixi inicialitzar el tamany de la variable histogram_bbdd_matrix \n",
    "for l in range(LevelMax):\n",
    "    numeroDeBlocs = (l+1)**2 + numeroDeBlocs\n",
    "#print(\"numeroDeBlocs:\", numeroDeBlocs)\n",
    "    \n",
    "histogram_bbdd_matrix_blocs = np.empty([0, numberBins*3*numeroDeBlocs]) #Creem una matriu buida\n",
    "#print(\"histogram_bbdd_matrix.shape\", histogram_bbdd_matrix.shape)\n",
    "\n",
    "def blockbasedHistogram_concatenatingLevels(img,levelMax):\n",
    "    \n",
    "    for lvl in range(levelMax): #Bucli per cobrir tots els levels i concatenarlos\n",
    "\n",
    "        #Calculem tamany del block\n",
    "        level = lvl + 1\n",
    "        #print(\"level: \", level)\n",
    "        height, width = img.shape[:2]\n",
    "        block_height = int(height/level)\n",
    "        block_width = int(width/level)\n",
    "        colorx = ('x','y','z')\n",
    "        canal = 0\n",
    "\n",
    "        for i,col in enumerate(colorx): #Bucle per recorrer els canals de cada imatge  \n",
    "            for r in range(level): #Bucle per recorrer els blocs d'una mateixa row\n",
    "                for c in range(level): #Bucle per recorrer els blocs d'una mateixa column\n",
    "\n",
    "                    block = img[r*block_height:r*block_height+block_height, c*block_width:c*block_width+block_width] \n",
    "                    hist = cv2.calcHist([block],[i],None,[numberBins],[0,256]) #Calculem histogrames per blocs\n",
    "                    hist_t = hist.transpose()      \n",
    "                    #print(hist_t.shape)\n",
    "                    if (i==0) and (r==0) and (c==0) and (lvl==0):\n",
    "                        hist_img = hist_t\n",
    "                    else:\n",
    "                        hist_img = np.concatenate((hist_img, hist_t), axis = 1)\n",
    "\n",
    "                    #print(hist_img.shape)\n",
    "\n",
    "\n",
    "    cv2.normalize(hist_img, hist_img, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    return hist_img\n",
    "\n",
    "for filename in sorted(listdir(imagesFolder)): #Bucle per recorrer les imatges de la bbdd\n",
    "    if(filename != '.DS_Store'):\n",
    "        print (\"\\r Processing image...   {}\".format(imagesFolder+filename), end=\"\")\n",
    "        img = cv2.imread(imagesFolder + filename)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2Lab)\n",
    "        hist_img = np.empty([0,0])\n",
    "        hist_img = blockbasedHistogram_concatenatingLevels(img, LevelMax)\n",
    "        histogram_bbdd_matrix_blocs = np.vstack((histogram_bbdd_matrix_blocs, hist_img))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279, 42240)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histogram_bbdd_matrix_blocs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogrames de les imatges de QSD2_W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing image...   ./qsd2_w1/00029.jpg"
     ]
    }
   ],
   "source": [
    "query2folder = './qsd2_w1/'\n",
    "histogram_query2_matrix = np.empty([0, numberBins*3*numeroDeBlocs])\n",
    "\n",
    "def blockbasedHistogram_concatenatingLevels_maskRemoval(query_img, mask, levelMax):\n",
    "    \n",
    "    #Compute the histogram\n",
    "    query_img = cv2.cvtColor(query_img,cv2.COLOR_BGR2Lab)\n",
    "    \n",
    "    #************************************************************************************************    \n",
    "\n",
    "    # CROP IMAGE\n",
    "    #************************************************************************************************\n",
    "    \n",
    "    # Mask of non-black pixels (assuming image has a single channel).\n",
    "    mask_rows, mask_columns = mask.shape\n",
    "    mask_crop = mask > 0\n",
    "\n",
    "    # Coordinates of non-black pixels.\n",
    "    coords = np.argwhere(mask_crop)\n",
    "\n",
    "    # Bounding box of non-black pixels.\n",
    "    x0, y0 = coords.min(axis=0)\n",
    "    x1, y1 = coords.max(axis=0) + 1   # slices are exclusive at the top\n",
    "\n",
    "    # Get the contents of the bounding box.\n",
    "    cropped = query_img[x0:x1, y0:y1]\n",
    "    mask_cropped = mask[x0:x1, y0:y1]\n",
    "    \n",
    "    #************************************************************************************************    \n",
    "\n",
    "    # CALCULEM ELS HISTOGRAMES DE LES IMATGES RETALLADES\n",
    "    #************************************************************************************************\n",
    "    hist_img = np.empty([0,0])\n",
    "    \n",
    "    color = ('b','g','r')\n",
    "\n",
    "    for lvl in range(levelMax): #Bucli per cobrir tots els levels i concatenarlos\n",
    "\n",
    "        level = lvl + 1\n",
    "        #Calculem tamany del block\n",
    "        height, width = cropped.shape[:2]\n",
    "        block_height = int(height/level)\n",
    "        block_width = int(width/level)\n",
    "\n",
    "        for i,col in enumerate(color):\n",
    "            for r in range(level): #Bucle per recorrer els blocs d'una mateixa row\n",
    "                for c in range(level): #Bucle per recorrer els blocs d'una mateixa column\n",
    "                    #print(\"canal: \", i)\n",
    "                    #print(\"r    : \", r)\n",
    "                    #print(\"c    : \", c)\n",
    "                    block = cropped[r*block_height:r*block_height+block_height, c*block_width:c*block_width+block_width] \n",
    "                    mask_block = mask_cropped[r*block_height:r*block_height+block_height, c*block_width:c*block_width+block_width]\n",
    "                    hist = cv2.calcHist([block],[i],mask_block,[numberBins],[0,256]) #Calculem histogrames per blocs\n",
    "                    hist_t = hist.transpose()  \n",
    "                    #print(hist_t.shape)\n",
    "                    #print(hist_img.shape)\n",
    "                    if (i==0) and (r==0) and (c==0) and (lvl==0):\n",
    "                        hist_query = hist_t\n",
    "                        #print(hist_query.shape)\n",
    "                    else:\n",
    "                        hist_query = np.concatenate((hist_query,hist_t), axis = 1)\n",
    "                        #print(hist_query.shape)\n",
    "\n",
    "    #print(histogram_query2_matrix.shape)\n",
    "    #print(hist_query.shape)\n",
    "    cv2.normalize(hist_query, hist_query, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    return hist_query\n",
    "    \n",
    "for filename in sorted(listdir(query2folder)):\n",
    "    if(filename != '.DS_Store' and (filename.split('.')[1] == 'jpg')):\n",
    "        print (\"\\r Processing image...   {}\".format(query2folder+filename), end=\"\")\n",
    "        query_img = cv2.imread(query2folder + filename)\n",
    "        \n",
    "        # Mask genetation\n",
    "        mask = mask_generator(query_img)\n",
    "        \n",
    "        #Save to the histogram_query matrix   \n",
    "        hist_query = blockbasedHistogram_concatenatingLevels_maskRemoval(query_img, mask, LevelMax)   \n",
    "        histogram_query2_matrix = np.vstack((histogram_query2_matrix, hist_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 42240)\n"
     ]
    }
   ],
   "source": [
    "print(histogram_query2_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2 (b) - Evaluation of TASK 1 (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.11111111111111"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=3\n",
    "matrix_retrieval = computeMatrixRetrieval(histogram_bbdd_matrix_blocs, histogram_query2_matrix, K)\n",
    "evaluationTask1(matrix_retrieval, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogrames de les imatges de QSD2_W1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3 & TASK 4 & TASK 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the functions used for following Tasks 3, 4, 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from PIL import ImageDraw, Image\n",
    "\n",
    "def detect_corners(mask):\n",
    "    \"\"\"\n",
    "    Finds four points corresponding to rectangle corners\n",
    "\n",
    "    :param mask: (ndarray) binary image\n",
    "    :return: (int) points from corners\n",
    "    \"\"\"\n",
    "\n",
    "    width = mask.shape[1]\n",
    "    height = mask.shape[0]\n",
    "    coords = np.argwhere(np.ones([height, width]))\n",
    "    coords_x = coords[:, 1]\n",
    "    coords_y = coords[:, 0]\n",
    "\n",
    "    coords_x_filtered = np.extract(mask, coords_x)\n",
    "    coords_y_filtered = np.extract(mask, coords_y)\n",
    "    max_br = np.argmax(coords_x_filtered + coords_y_filtered)\n",
    "    max_tr = np.argmax(coords_x_filtered - coords_y_filtered)\n",
    "    max_tl = np.argmax(-coords_x_filtered - coords_y_filtered)\n",
    "    max_bl = np.argmax(-coords_x_filtered + coords_y_filtered)\n",
    "\n",
    "    tl_x, tl_y = int(coords_x_filtered[max_tl]), int(coords_y_filtered[max_tl])\n",
    "    tr_x, tr_y = int(coords_x_filtered[max_tr]), int(coords_y_filtered[max_tr])\n",
    "    bl_x, bl_y = int(coords_x_filtered[max_bl]), int(coords_y_filtered[max_bl])\n",
    "    br_x, br_y = int(coords_x_filtered[max_br]), int(coords_y_filtered[max_br])\n",
    "\n",
    "    return tl_x, tl_y, bl_x, bl_y, br_x, br_y, tr_x, tr_y\n",
    "\n",
    "def text_detect_method1(img, opt = 0):\n",
    "    \"\"\"\n",
    "    Text bounding box detection\n",
    "\n",
    "    :param img: (ndarray) query image\n",
    "    :param opt: (int) options to corner detection (0 or 1)\n",
    "    :return: bbox: (tuple of int) bounding box, (tlx, tly, brx, bry)\n",
    "    \"\"\"\n",
    "\n",
    "    bifilter = cv2.bilateralFilter(img, 9, 300, 300)\n",
    "\n",
    "    hsv = cv2.cvtColor(bifilter, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    ret, thresh = cv2.threshold(hsv[:, :, 1], 0, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, np.ones((7, 7), np.uint8))\n",
    "    open1 = cv2.morphologyEx(closing, cv2.MORPH_OPEN, np.ones((10, 1), np.uint8), iterations=2)\n",
    "    open2 = cv2.morphologyEx(open1, cv2.MORPH_OPEN, np.ones((1, 10), np.uint8), iterations=2)\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.imshow(open2, cmap = 'gray')\n",
    "\n",
    "    ret, labels = cv2.connectedComponents(open2)\n",
    "    # plt.figure()\n",
    "    # plt.imshow(labels, cmap = 'gray')\n",
    "\n",
    "    area = []\n",
    "    for i, lab in enumerate(np.unique(labels)):\n",
    "        area.append(open2[labels == lab].size)\n",
    "    idx = sorted(range(len(area)), key=lambda k: area[k])\n",
    "\n",
    "    x_n = open2.shape[0]\n",
    "    nbb = list(range(int((x_n / 2) - x_n * (0.05)), int((x_n / 2) + x_n * (0.05))))\n",
    "\n",
    "    if ret > 2:\n",
    "        for i, j in enumerate(idx):\n",
    "            if np.sum(open2[labels == j] == 0) == 0:\n",
    "                idn = np.where(labels == j)[0]\n",
    "                nocenter = [val for val in idn.tolist() if val in nbb]\n",
    "\n",
    "                if (len(area) - i) > 2:\n",
    "                    open2[labels == j] = 0\n",
    "\n",
    "                if (len(area) - i) <= 2 and len(nocenter) > 0:\n",
    "                    open2[labels == j] = 0\n",
    "                    open2[labels == idx[i - 1]] = 255\n",
    "\n",
    "\n",
    "\n",
    "    if opt == 0:\n",
    "\n",
    "        # Coordinates of non-black pixels.\n",
    "        coords = np.argwhere(open2)\n",
    "\n",
    "        # Bounding box of non-black pixels.\n",
    "        x0, y0 = coords.min(axis=0)\n",
    "        x1, y1 = coords.max(axis=0) + 1\n",
    "\n",
    "    else:\n",
    "        y0, x0, _, _, y1, x1, _, _ = detect_corners(open2)\n",
    "\n",
    "    bbox = (y0, x0, y1, x1)\n",
    "\n",
    "    return bbox\n",
    "\n",
    "def evaluationTask5(matrix_retrieval, K=10):  \n",
    "    #LLEGIR GT\n",
    "    with open('./qsd1_w2/' + 'gt_corresps.pkl', 'rb') as fd:\n",
    "            ll = pickle.load(fd)\n",
    "            #print(ll)\n",
    "    gt = np.empty((0,0))\n",
    "\n",
    "    ll_prp = np.zeros((len(ll),1))\n",
    "\n",
    "    for i in range(0,len(ll)):\n",
    "        ll_prp[i] = ll[i][0]\n",
    "\n",
    "    ll_prp_lst = ll_prp.tolist()\n",
    "\n",
    "    mapak = metrics.average_precision.mapk(ll_prp_lst, matrix_retrieval, k=K)    \n",
    "    score = mapak*100\n",
    "    #print(\"SCORE: \",score, \"%\")\n",
    "\n",
    "    #GUARDAR PICKLE RESULT\n",
    "    pickle_out = open(\"./result_qsd1_w2.pkl\", \"wb\")\n",
    "    pickle.dump(matrix_retrieval, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text detection and evaluation using bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing image...   ./qsd1_w2/00029.jpg"
     ]
    }
   ],
   "source": [
    "from evaluation.bbox_iou import bbox_iou\n",
    "\n",
    "query2folder = './qsd1_w2/'\n",
    "\n",
    "with open(query2folder+'text_boxes.pkl', 'rb') as fd:\n",
    "    ll = pickle.load(fd)\n",
    "\n",
    "\n",
    "IoU = []\n",
    "histogram_query1w2_matrix = np.empty([0, numberBins*3*Level**2])\n",
    "\n",
    "bboxes1 = []\n",
    "\n",
    "for filename in sorted(listdir(query2folder)):\n",
    "    count = 0\n",
    "    if (filename != '.DS_Store' and (filename.split('.')[1] == 'jpg')):\n",
    "\n",
    "        # Read image and its mask\n",
    "        query_img = cv2.imread(query2folder + filename)\n",
    "        mask = np.ones((query_img.shape[0],query_img.shape[1]),dtype='uint8')*255\n",
    "        \n",
    "        # Image number\n",
    "        img_num = int(filename[0:5])\n",
    "        bbox_gt = ll[img_num][0]\n",
    "\n",
    "        # Search bbox for text\n",
    "        bbox = text_detect_method1(query_img)\n",
    "\n",
    "        # Set tl and br for predicted and ground truth\n",
    "        y0, x0, y1, x1 = bbox\n",
    "        bboxes1.append([[y0, x0, y1, x1]])\n",
    "        y0_gt, x0_gt, y1_gt, x1_gt = bbox_gt\n",
    "        \n",
    "        # Save image with both bbox\n",
    "        #cv2.rectangle(query_img, (y0, x0), (y1, x1), (0, 0, 255), 2)\n",
    "        #cv2.rectangle(query_img, (y0_gt, x0_gt), (y1_gt, x1_gt), (0, 255, 0), 2)\n",
    "        #cv2.imwrite('bbox_'+filename, query_img)\n",
    "\n",
    "        ### TASK 4 ###\n",
    "    \n",
    "        # Compute metric IoU\n",
    "        IoU.append(bbox_iou(bbox, bbox_gt))\n",
    "        \n",
    "        ### TASK 5 ###\n",
    "        \n",
    "        # Ignore pixels from bbox\n",
    "        mask[x0:x1, y0:y1] = 0\n",
    "        \n",
    "        print (\"\\r Processing image...   {}\".format(query2folder+filename), end=\"\")\n",
    "        \n",
    "        #Save to the histogram_query matrix\n",
    "        hist_query = blockbasedHistogram_oneLevel_maskRemoval(query_img, mask, Level)\n",
    "        histogram_query1w2_matrix = np.vstack((histogram_query1w2_matrix, hist_query))\n",
    "\n",
    "#GUARDAR PICKLE RESULT\n",
    "pickle_out = open(\"boxes1.pkl\", \"wb\")\n",
    "pickle.dump(bboxes1, pickle_out)\n",
    "pickle_out.close()\n",
    "#print('\\n\\nMetric mean IoU:', np.mean(IoU))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 5 (b) - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.22222222222221"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=10\n",
    "matrix_retrieval = computeMatrixRetrieval(histogram_bbdd_matrix, histogram_query1w2_matrix, K)\n",
    "evaluationTask5(matrix_retrieval, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the functions used for Tasks 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw, Image\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "def waterShed(query_img, sat, part):\n",
    "    \"\"\"\n",
    "    Applies watershed to detect foreground and baskground\n",
    "\n",
    "    :param query_img: (ndarray) query image\n",
    "    :param sat: (ndarray) query image saturation\n",
    "    :param part: (int) one paint(0), two paints left part(1),  two paints right part(2)\n",
    "    :return: mask: predicted mask\n",
    "    \"\"\"\n",
    "\n",
    "    ret, thresh = cv2.threshold(sat, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    thresh = 255 - thresh\n",
    "\n",
    "    # noise removal\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    # fillin holes\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    opening = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)  # Fals. El sure\n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 3)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.13 * dist_transform.max(), 255, 0)  # 0.15 26.57%\n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    markers[markers != 0] = 200\n",
    "\n",
    "    border_top = int(sat.shape[0] * .03)\n",
    "\n",
    "    if part != 2:\n",
    "        border_r = int(sat.shape[1] * .01)\n",
    "        border_l = int(sat.shape[1] * .02)\n",
    "    if part != 1:\n",
    "        border_r = int(sat.shape[1] * .02)\n",
    "        border_l = int(sat.shape[1] * .01)\n",
    "\n",
    "\n",
    "    # define known sure background\n",
    "    markers[0:border_top, :] = 100\n",
    "    sure_fg[0:border_top, :] = 100\n",
    "\n",
    "    markers[len(markers) - border_top:len(markers) - 1, :] = 100\n",
    "    sure_fg[len(markers) - border_top:len(markers) - 1, :] = 100\n",
    "\n",
    "    markers[:, 0:border_l] = 100\n",
    "    sure_fg[:, 0:border_l] = 100\n",
    "    markers[:, len(markers[0, :]) - border_r:len(markers[0, :]) - 1] = 100\n",
    "    sure_fg[:, len(markers[0, :]) - border_r:len(markers[0, :]) - 1] = 100\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[sure_fg == 0] = 0\n",
    "\n",
    "    markersres = cv2.watershed(query_img, markers)\n",
    "\n",
    "    markersres[markersres == 201] = 255\n",
    "    markersres[markersres == 101] = 0\n",
    "    markersres[markersres == -1] = 255\n",
    "\n",
    "    # Make the mask binary\n",
    "    return markersres / np.max(markersres)\n",
    "\n",
    "\n",
    "def crop(query_im, mask_crop):\n",
    "    # Coordinates of non-black pixels.\n",
    "    coords = np.argwhere(mask_crop)\n",
    "\n",
    "    # Bounding box of non-black pixels.\n",
    "    x0, y0 = coords.min(axis=0)\n",
    "    x1, y1 = coords.max(axis=0) + 1   # slices are exclusive at the top\n",
    "\n",
    "    # Get the contents of the bounding box.\n",
    "    cropped = query_im[x0:x1, y0:y1]\n",
    "    mask_cropped = mask_crop[x0:x1, y0:y1]\n",
    "    \n",
    "    return cropped, mask_cropped, x0, y0\n",
    "    \n",
    "\n",
    "\n",
    "def computeMatrixRetrievalTask6(histogram_bbdd, histogram_query, img_list, K=10):\n",
    "    \n",
    "    dst = np.zeros((histogram_query.shape[0], 279))\n",
    "    matrix_retrieval = np.zeros((histogram_query.shape[0],K))\n",
    "    \n",
    "    for query_image_index in range(0,len(histogram_query)): \n",
    "        for bbdd_image_index in range(0, len(histogram_bbdd)):\n",
    "\n",
    "            dst[query_image_index,bbdd_image_index] = distance.braycurtis(histogram_query[query_image_index,:], histogram_bbdd[bbdd_image_index,:])\n",
    "\n",
    "        matrix_retrieval[query_image_index,:] = np.argsort(dst[query_image_index,:])[:K]\n",
    "    \n",
    "    new_matrix_retrieval = []\n",
    "    index_per_matrix_retrieval = 0\n",
    "    for ind, num_images in enumerate(img_list):\n",
    "        if(len(num_images)>1):\n",
    "            aux = []\n",
    "            aux_1 = (matrix_retrieval[index_per_matrix_retrieval].astype(int)).tolist()\n",
    "            aux_2 = (matrix_retrieval[index_per_matrix_retrieval+1].astype(int)).tolist()\n",
    "            aux.append(aux_1)\n",
    "            aux.append(aux_2)\n",
    "            new_matrix_retrieval.append(aux)\n",
    "            index_per_matrix_retrieval = index_per_matrix_retrieval + 2\n",
    "        else:\n",
    "            aux = []\n",
    "            aux_1 = (matrix_retrieval[index_per_matrix_retrieval].astype(int)).tolist()\n",
    "            aux_2 = []\n",
    "            aux.append(aux_1)\n",
    "            aux.append(aux_2)\n",
    "            new_matrix_retrieval.append(aux)\n",
    "            index_per_matrix_retrieval = index_per_matrix_retrieval + 1\n",
    "    \n",
    "    return new_matrix_retrieval\n",
    "\n",
    "\n",
    "def evaluationTask6(matrix_retrieval, K=10):\n",
    "    #LLEGIR GT\n",
    "    with open('./qsd2_w2/' + 'gt_corresps.pkl', 'rb') as fd:\n",
    "            ll = pickle.load(fd)\n",
    "            \n",
    "    for l in range(len(ll)):\n",
    "        if len(ll[l]) < 2:\n",
    "            ll[l].append([])\n",
    "            \n",
    "    mapak = metrics.average_precision.mapk(ll, matrix_retrieval, k=K)    \n",
    "    score = mapak*100\n",
    "    print(\"SCORE: \",score, \"%\")\n",
    "\n",
    "    #GUARDAR PICKLE RESULT\n",
    "    pickle_out = open(\"result_qsd2_w2.pkl\", \"wb\")\n",
    "    pickle.dump(matrix_retrieval, pickle_out)\n",
    "    pickle_out.close()\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect paintings, remove background and text and return correspondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing image...   ./qsd2_w2/00029.jpg"
     ]
    }
   ],
   "source": [
    "# initialize pixel mask\n",
    "mask_gt_pixel = np.empty([1])\n",
    "mask_pred_pixel = np.empty([1])\n",
    "\n",
    "query2folder = './qsd2_w2/'\n",
    "histogram_query2w2_matrix = np.empty([0, numberBins*3*Level**2])\n",
    "\n",
    "img_l = []\n",
    "bboxes = []\n",
    "\n",
    "for filename in sorted(listdir(query2folder)):\n",
    "    count = 0\n",
    "    if (filename != '.DS_Store' and (filename.split('.')[1] == 'jpg')):\n",
    "\n",
    "        # Read query image\n",
    "        mask_gt = cv2.cvtColor(cv2.imread(query2folder + filename[0:-3] + 'png'), cv2.COLOR_BGR2GRAY) / 255\n",
    "        query_img = cv2.imread(query2folder + filename)\n",
    "        gray = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Get saturation from query image\n",
    "        sat = cv2.cvtColor(query_img, cv2.COLOR_BGR2HSV)[:,:,1]\n",
    "        \n",
    "        # Divide image in two if weight is 1.6 superior than height\n",
    "        if sat.shape[1] >= sat.shape[0]*1.6:\n",
    "            \n",
    "            # Predict masks for each half part of the image\n",
    "            markersres1 = waterShed(query_img[:, 0:int(sat.shape[1]/2)],sat[:, 0:int(sat.shape[1]/2)], 1)\n",
    "            markersres2 = waterShed(query_img[:, int(sat.shape[1] / 2)-1:-1], sat[:, int(sat.shape[1] / 2)-1:-1], 2)\n",
    "            \n",
    "            # Concatenate predicitons\n",
    "            markersres = np.concatenate((markersres1, markersres2), axis=1)\n",
    "            \n",
    "            # Remove imperfections with morphological filers (fill holes and remove noise)\n",
    "            markersres = cv2.morphologyEx(markersres, cv2.MORPH_OPEN, np.ones((3,3), np.uint8), iterations=1)\n",
    "            markersres = cv2.morphologyEx(markersres, cv2.MORPH_CLOSE, np.ones((1,40), np.uint8), iterations=1)\n",
    "            markersres = cv2.morphologyEx(markersres, cv2.MORPH_CLOSE, np.ones((40, 1), np.uint8), iterations=1)\n",
    "\n",
    "        else :\n",
    "            # Predict mask\n",
    "            markersres = waterShed(query_img, sat, 0)\n",
    "            \n",
    "            # Remove imperfections with morphological filers (noise)\n",
    "            markersres = cv2.morphologyEx(markersres, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "        # Set predicted mask\n",
    "        mask_pred = markersres.astype('uint8')\n",
    "\n",
    "        # Get connected components\n",
    "        ret, labels = cv2.connectedComponents(mask_pred)\n",
    "        \n",
    "        # Initialize mask for paintings\n",
    "        mask = np.zeros((mask_pred.shape[0], mask_pred.shape[1], 2), dtype=\"uint8\")\n",
    "        \n",
    "        # If exist more than two connected components (background and one painting)\n",
    "        if ret > 2:\n",
    "\n",
    "            # Compute area of each connected component\n",
    "            area = []\n",
    "            for i, lab in enumerate(np.unique(labels)):\n",
    "                area.append(mask_pred[labels == lab].size)\n",
    "                \n",
    "            # Sort indexes from length of areas\n",
    "            idx = sorted(range(len(area)), key=lambda k: area[k])\n",
    "\n",
    "            # Check if more than three connected components (background and two paintings)\n",
    "            if ret > 3:\n",
    "                for i, j in enumerate(idx):\n",
    "                    # Remove smallest areas\n",
    "                    if (len(area)-i) > 3:\n",
    "                        mask_pred[labels == j] = 0\n",
    "            \n",
    "            # Remove indexes labels where its pixels are now zero\n",
    "            idx = [n for _, n in enumerate(idx) if np.sum(mask_pred[labels == n]) != 0]\n",
    "            \n",
    "            # Positions of non-zero elements of each painting\n",
    "            obj1 = np.where(labels == idx[0])\n",
    "            obj2 = np.where(labels == idx[1])\n",
    "            \n",
    "            # Determine if there exist two paintings\n",
    "            if (area[idx[0]] > .28*area[idx[1]]):\n",
    "                \n",
    "                # Check that one connected component is not inside the other\n",
    "                if (((np.min(obj1[1][:]) - np.max(obj2[1][:])) < 0) and ((np.max(obj1[1][:]) - np.min(obj2[1][:])) > 0)) \\\n",
    "                        or (((np.min(obj2[1][:]) - np.max(obj1[1][:])) < 0) and\n",
    "                            ((np.max(obj2[1][:]) - np.min(obj1[1][:])) > 0)):\n",
    "                    mask = mask_pred\n",
    "                else:\n",
    "                    # Set one mask to each painting\n",
    "                    mask[labels == idx[0], 0] = 1\n",
    "                    mask[labels == idx[1], 1] = 1\n",
    "\n",
    "            else:\n",
    "                # Set mask for the painting\n",
    "                mask = mask_pred\n",
    "\n",
    "        else:\n",
    "            # Set mask for the painting\n",
    "            mask = mask_pred\n",
    "\n",
    "        ## POLYGON - Generate a polygon from mask corners ##\n",
    "        \n",
    "        mask_f = np.zeros((mask_pred.shape[0], mask_pred.shape[1], 2), dtype=\"uint8\")\n",
    "        \n",
    "        # For two paintings\n",
    "        if len(mask.shape) > 2:\n",
    "            # Get Corners\n",
    "            corners0 = detect_corners(mask[:, :, 0])\n",
    "            \n",
    "            # Draw polygon\n",
    "            poly0 = Image.new('RGB', (mask_pred.shape[1], mask_pred.shape[0]), (0))\n",
    "            pdraw0 = ImageDraw.Draw(poly0)\n",
    "            pdraw0.polygon(xy=corners0, fill=(1), outline=None)\n",
    "            mask_pred_f = np.array(poly0)[:, :, 0]\n",
    "            mask_f[:, :, 0] = mask_pred_f\n",
    "            \n",
    "            # Get Corners\n",
    "            corners1 = detect_corners(mask[:, :, 1])\n",
    "            \n",
    "            # Draw polygon\n",
    "            poly1 = Image.new('RGB', (mask_pred.shape[1], mask_pred.shape[0]), (0))\n",
    "            pdraw1 = ImageDraw.Draw(poly1)\n",
    "            pdraw1.polygon(xy=corners1, fill=(1), outline=None)\n",
    "            mask_f[:, :, 1] = np.array(poly1)[:, :, 0]\n",
    "            mask_pred_f = mask_pred_f + mask_f[:, :, 1]\n",
    "\n",
    "        # Just one painting\n",
    "        else:\n",
    "            # Get Corners\n",
    "            corners = detect_corners(mask)\n",
    "            \n",
    "            # Draw polygon\n",
    "            poly = Image.new('RGB', (mask_pred.shape[1], mask_pred.shape[0]), (0))\n",
    "            pdraw = ImageDraw.Draw(poly)\n",
    "            pdraw.polygon(xy=corners, fill=(1), outline=None)\n",
    "            mask_pred_f = np.array(poly)[:, :, 0]\n",
    "            mask_f = mask_pred_f\n",
    "            \n",
    "        # Save mask as image\n",
    "        #cv2.imwrite(filename[0:-3]+'png', mask_pred_f*255)\n",
    "\n",
    "        # Concatenate all pixels from all images\n",
    "        #mask_gt_pixel = np.concatenate((mask_gt_pixel, mask_gt.flatten()), axis=0)\n",
    "        #mask_pred_pixel = np.concatenate((mask_pred_pixel, mask_pred_f.flatten()), axis=0)\n",
    "        \n",
    "        print (\"\\r Processing image...   {}\".format(query2folder+filename), end=\"\")\n",
    "        \n",
    "        if len(mask.shape) > 2:\n",
    "            \n",
    "            img_l.append([0,0])\n",
    "            \n",
    "            box = []\n",
    "            \n",
    "            for p in range(2):\n",
    "                \n",
    "                cropped, mask_cropped, X0, Y0 = crop(query_img,mask_f[:,:,p])\n",
    "                \n",
    "                # Detect bbox\n",
    "                bbox = text_detect_method1(cropped)\n",
    "                y0, x0, y1, x1 = bbox\n",
    "                mask_cropped[x0:x1, y0:y1] = 0\n",
    "                box.append([Y0+y0, X0+x0, Y0+y1, X0+x1])\n",
    "                \n",
    "                #cv2.rectangle(query_img, (Y0+y0, X0+x0), (Y0+y1, X0+x1), (0, 0, 255), 2)\n",
    "                #cv2.imwrite('bbox_'+filename, query_img)\n",
    "                \n",
    "                #Save to the histogram_query matrix each painting histogram\n",
    "                hist_query = blockbasedHistogram_oneLevel_maskRemoval(cropped, mask_cropped, Level)\n",
    "                histogram_query2w2_matrix = np.vstack((histogram_query2w2_matrix, hist_query))\n",
    "                \n",
    "            bboxes.append(box)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            img_l.append([0])\n",
    "            \n",
    "            cropped, mask_cropped, X0, Y0 = crop(query_img,mask_f)\n",
    "\n",
    "            bbox = text_detect_method1(cropped)\n",
    "            y0, x0, y1, x1 = bbox\n",
    "            mask_cropped[x0:x1, y0:y1] = 0\n",
    "            \n",
    "            #cv2.rectangle(query_img, (Y0+y0, X0+x0), (Y0+y1, X0+x1), (0, 0, 255), 2)\n",
    "            #cv2.imwrite('bbox_'+filename, query_img)\n",
    "            \n",
    "            bboxes.append([[Y0+y0, X0+x0, Y0+y1, X0+x1]])\n",
    "\n",
    "            #Save to the histogram_query matrix each painting histogram\n",
    "            hist_query = blockbasedHistogram_oneLevel_maskRemoval(cropped, mask_cropped, Level)\n",
    "            histogram_query2w2_matrix = np.vstack((histogram_query2w2_matrix, hist_query))\n",
    "            \n",
    "\n",
    "# Mask evaluation\n",
    "#mask_gt_pixel = mask_gt_pixel[1:]\n",
    "#mask_pred_pixel = mask_pred_pixel[1:]\n",
    "\n",
    "#PRECISION\n",
    "#precision = precision_score(mask_gt_pixel, mask_pred_pixel)\n",
    "#RECALL\n",
    "#recall = recall_score(mask_gt_pixel, mask_pred_pixel)\n",
    "#F1\n",
    "#f1 = f1_score(mask_gt_pixel, mask_pred_pixel)\n",
    "\n",
    "#print('PRECISION: ', precision, 'RECALL: ', recall, ' F1-SCORE: ', f1)\n",
    "\n",
    "#GUARDAR PICKLE RESULT\n",
    "pickle_out = open(\"text_boxes2.pkl\", \"wb\")\n",
    "pickle.dump(bboxes, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:  19.166666666666668 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.166666666666668"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_retrieval = computeMatrixRetrievalTask6(histogram_bbdd_matrix, histogram_query2w2_matrix, img_l, K=10)\n",
    "evaluationTask6(matrix_retrieval, K=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
