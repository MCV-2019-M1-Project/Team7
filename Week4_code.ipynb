{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 4 CODE\n",
    "\n",
    "### Content:\n",
    "* TASK 1: Detect keypoints and compute descriptors in Museum and query images\n",
    "* TASK 2: Find tentative matches based on similarity of local appearance and verify matches\n",
    "* TASK 3: Evaluate the system on QSD1-W4, map@k\n",
    "* TASK 4: Evaluate best system from previous week on QSD1-W4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import math\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import matplotlib.patches as patches\n",
    "import ml_metrics as metrics\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score\n",
    "from scipy.spatial import distance\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.fftpack import dct\n",
    "from scipy import ndimage\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature import hog\n",
    "from skimage.filters import roberts, sobel, sobel_h, sobel_v\n",
    "from skimage.morphology import skeletonize, dilation, square, opening, closing, erosion\n",
    "from pathlib import Path\n",
    "from cv2 import boundingRect\n",
    "from cv2 import xfeatures2d_SIFT\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing: Filter noise with linear or non-linear filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE FUNCTIONS \n",
    "\n",
    "def detectnoise(img):\n",
    "    # Calcula la sigma del soroll. Llavors les imatges que tenen soroll tenen una sigma mÃ©s gran \n",
    "    #que la resta de les imatges\n",
    "    thr = 8.0\n",
    "    H, W = gray.shape\n",
    "\n",
    "    M = [[1, -2, 1],\n",
    "        [-2, 4, -2],\n",
    "        [1, -2, 1]]\n",
    "    \n",
    "    sigma = np.sum(np.sum(np.absolute(convolve2d(gray, M))))\n",
    "    sigma = sigma * math.sqrt(0.5 * math.pi) / (6 * (W-2) * (H-2))\n",
    "    if sigma>thr:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2folder = './qsd1_w4/'\n",
    "\n",
    "# CREEM UN DIRECTORI ON GUARDEM LES IMATGES SENSE SOROLL\n",
    "path = 'qsd1_w4_denoise'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "\n",
    "for filename in sorted(listdir(query2folder)):\n",
    "    if(filename != '.DS_Store' and ('jpg' in filename)):\n",
    "        print (\"\\r Processing image...   {}\".format(query2folder+filename), end=\"\")\n",
    "        query_img = cv2.imread(query2folder + filename)\n",
    "        gray = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)\n",
    "        noise = detectnoise(gray)\n",
    "        if noise:\n",
    "            denoise_img = cv2.bilateralFilter(query_img, 9, 120, 120)\n",
    "            denoise_img_2 = cv2.fastNlMeansDenoisingColored(denoise_img,None,12,10,7,21) \n",
    "        else:\n",
    "            denoise_img_2 = query_img\n",
    "        \n",
    "        cv2.imwrite(os.path.join(path,filename), denoise_img_2)\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Detect keypoints and compute descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING FUNCTIONS FOR TASK 1\n",
    "\n",
    "def findKeypoints(img, descriptor):\n",
    "    \n",
    "    if descriptor is 'SIFT':\n",
    "        # Initiate SIFT detector\n",
    "        sift = xfeatures2d_SIFT.create()\n",
    "\n",
    "        # find the keypoints and descriptors with SIFT\n",
    "        kp, des = sift.detectAndCompute(img, None)\n",
    "    elif descriptor is 'ORB':\n",
    "        # Initiate ORB detector\n",
    "        orb = cv2.ORB_create()\n",
    "        \n",
    "        # find the keypoints and descriptors with ORB\n",
    "        kp = orb.detect(img, None)\n",
    "        kp, des = orb.compute(img, kp)\n",
    "    \n",
    "    elif descriptor is 'SURF':\n",
    "        # Initiate SURF detector\n",
    "        surf = xfeatures2d_SURF.create()\n",
    "\n",
    "        # find the keypoints and descriptors with SIFT\n",
    "        kp, des = surf.detectAndCompute(img, None)\n",
    "\n",
    "    return kp,des\n",
    "\n",
    "\n",
    "# FUNCTIONS BACKGROUND DETECTION \n",
    "\n",
    "def detect_corners(mask):\n",
    "    \"\"\"\n",
    "    Finds four points corresponding to rectangle corners\n",
    "\n",
    "    :param mask: (ndarray) binary image\n",
    "    :return: (int) points from corners\n",
    "    \"\"\"\n",
    "\n",
    "    width = mask.shape[1]\n",
    "    height = mask.shape[0]\n",
    "    coords = np.argwhere(np.ones([height, width]))\n",
    "    coords_x = coords[:, 1]\n",
    "    coords_y = coords[:, 0]\n",
    "\n",
    "    coords_x_filtered = np.extract(mask, coords_x)\n",
    "    coords_y_filtered = np.extract(mask, coords_y)\n",
    "    max_br = np.argmax(coords_x_filtered + coords_y_filtered)\n",
    "    max_tr = np.argmax(coords_x_filtered - coords_y_filtered)\n",
    "    max_tl = np.argmax(-coords_x_filtered - coords_y_filtered)\n",
    "    max_bl = np.argmax(-coords_x_filtered + coords_y_filtered)\n",
    "\n",
    "    tl_x, tl_y = int(coords_x_filtered[max_tl]), int(coords_y_filtered[max_tl])\n",
    "    tr_x, tr_y = int(coords_x_filtered[max_tr]), int(coords_y_filtered[max_tr])\n",
    "    bl_x, bl_y = int(coords_x_filtered[max_bl]), int(coords_y_filtered[max_bl])\n",
    "    br_x, br_y = int(coords_x_filtered[max_br]), int(coords_y_filtered[max_br])\n",
    "\n",
    "    return tl_x, tl_y, bl_x, bl_y, br_x, br_y, tr_x, tr_y\n",
    "\n",
    "def waterShed(query_img, color_space, sat_chan):\n",
    "    \"\"\"\n",
    "    Applies watershed to detect foreground and baskground\n",
    "\n",
    "    :param query_img: (ndarray) query image\n",
    "    :param sat: (ndarray) query image saturation\n",
    "    :param part: (int) one paint(0), two paints left part(1),  two paints right part(2)\n",
    "    :return: mask: predicted mask\n",
    "    \"\"\"\n",
    "    \n",
    "    if sat_chan:\n",
    "        ret, thresh = cv2.threshold(color_space, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        thresh_pos = np.where(thresh==255)\n",
    "        if np.sum(thresh_pos[0]==0)>.7*thresh.shape[0] or np.sum(thresh_pos[1]==0)>.7*thresh.shape[1]:\n",
    "            thresh = 255 - thresh\n",
    "    else:\n",
    "        thresh = k_means(color_space)\n",
    "        thresh_pos = np.where(thresh==255)\n",
    "        if np.sum(thresh_pos[0]==0)>.7*thresh.shape[0] or np.sum(thresh_pos[1]==0)>.7*thresh.shape[1]:\n",
    "            thresh = 255 - thresh\n",
    "    \n",
    "    # noise removal\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    # fillin holes\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    opening = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)  # Fals. El sure\n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 3)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.05 * dist_transform.max(), 255, 0)  # 0.15 26.57%\n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    markers[markers != 0] = 200\n",
    "\n",
    "    border_top = int(sat.shape[0] * .03)\n",
    "    borde_lat = int(sat.shape[1] * .02)\n",
    "\n",
    "    # define known sure background\n",
    "    markers[0:border_top, :] = 100\n",
    "    sure_fg[0:border_top, :] = 100\n",
    "\n",
    "    markers[len(markers) - border_top:len(markers) - 1, :] = 100\n",
    "    sure_fg[len(markers) - border_top:len(markers) - 1, :] = 100\n",
    "\n",
    "    markers[:, 0:borde_lat] = 100\n",
    "    sure_fg[:, 0:borde_lat] = 100\n",
    "    markers[:, len(markers[0, :]) - borde_lat:len(markers[0, :]) - 1] = 100\n",
    "    sure_fg[:, len(markers[0, :]) - borde_lat:len(markers[0, :]) - 1] = 100\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[sure_fg == 0] = 0\n",
    "\n",
    "    markersres = cv2.watershed(query_img, markers)\n",
    "\n",
    "    markersres[markersres == 201] = 255\n",
    "    markersres[markersres == 101] = 0\n",
    "    markersres[markersres == -1] = 255\n",
    "\n",
    "    # Make the mask binary\n",
    "    markersres = markersres / np.max(markersres)\n",
    "            \n",
    "    # Remove imperfections with morphological filers (noise)\n",
    "    markersres = cv2.morphologyEx(markersres, cv2.MORPH_OPEN, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "    # Set predicted mask\n",
    "    mask_pred = markersres.astype('uint8')\n",
    "\n",
    "    # Get connected components\n",
    "    ret, labels = cv2.connectedComponents(mask_pred)\n",
    "\n",
    "    # Initialize mask for paintings\n",
    "    mask = np.zeros((mask_pred.shape[0], mask_pred.shape[1], 2), dtype=\"uint8\")\n",
    "\n",
    "    # If exist more than two connected components (background and one painting)\n",
    "    if ret > 2:\n",
    "\n",
    "        # Compute area of each connected component\n",
    "        area = []\n",
    "        for i, lab in enumerate(np.unique(labels)):\n",
    "            area.append(mask_pred[labels == lab].size)\n",
    "\n",
    "        # Sort indexes from length of areas\n",
    "        idx = sorted(range(len(area)), key=lambda k: area[k])\n",
    "\n",
    "        # Check if more than three connected components (background and two paintings)\n",
    "        if ret > 3:\n",
    "            for i, j in enumerate(idx):\n",
    "                # Remove smallest areas\n",
    "                if (len(area)-i) > 3:\n",
    "                    mask_pred[labels == j] = 0\n",
    "\n",
    "        # Remove indexes labels where its pixels are now zero\n",
    "        idx = [n for _, n in enumerate(idx) if np.sum(mask_pred[labels == n]) != 0]\n",
    "\n",
    "        # Positions of non-zero elements of each painting\n",
    "        obj1 = np.where(labels == idx[0])\n",
    "        obj2 = np.where(labels == idx[1])\n",
    "\n",
    "        # Determine if there exist two paintings\n",
    "        if (area[idx[0]] > .28*area[idx[1]]):\n",
    "\n",
    "            # Check that one connected component is not inside the other\n",
    "            if (((np.min(obj1[1][:]) - np.max(obj2[1][:])) < 0) and ((np.max(obj1[1][:]) - np.min(obj2[1][:])) > 0)) \\\n",
    "                    or (((np.min(obj2[1][:]) - np.max(obj1[1][:])) < 0) and\n",
    "                        ((np.max(obj2[1][:]) - np.min(obj1[1][:])) > 0)):\n",
    "                mask = mask_pred\n",
    "            else:\n",
    "                # Set one mask to each painting\n",
    "                mask[labels == idx[0], 0] = 1\n",
    "                mask[labels == idx[1], 1] = 1\n",
    "\n",
    "        else:\n",
    "            # Set mask for the painting\n",
    "            mask = mask_pred\n",
    "\n",
    "    else:\n",
    "        # Set mask for the painting\n",
    "        mask = mask_pred\n",
    "\n",
    "    ## POLYGON - Generate a polygon from mask corners ##\n",
    "\n",
    "    mask_f = np.zeros((mask_pred.shape[0], mask_pred.shape[1], 2), dtype=\"uint8\")\n",
    "\n",
    "    # For two paintings\n",
    "    if len(mask.shape) > 2:\n",
    "        # Get Corners\n",
    "        corners0 = detect_corners(mask[:, :, 0])\n",
    "\n",
    "        # Draw polygon\n",
    "        poly0 = Image.new('RGB', (mask_pred.shape[1], mask_pred.shape[0]), (0))\n",
    "        pdraw0 = ImageDraw.Draw(poly0)\n",
    "        pdraw0.polygon(xy=corners0, fill=(1), outline=None)\n",
    "        mask_pred_f = np.array(poly0)[:, :, 0]\n",
    "        mask_f[:, :, 0] = mask_pred_f\n",
    "\n",
    "        # Get Corners\n",
    "        corners1 = detect_corners(mask[:, :, 1])\n",
    "\n",
    "        # Draw polygon\n",
    "        poly1 = Image.new('RGB', (mask_pred.shape[1], mask_pred.shape[0]), (0))\n",
    "        pdraw1 = ImageDraw.Draw(poly1)\n",
    "        pdraw1.polygon(xy=corners1, fill=(1), outline=None)\n",
    "        mask_f[:, :, 1] = np.array(poly1)[:, :, 0]\n",
    "        mask_pred_f = mask_pred_f + mask_f[:, :, 1]\n",
    "\n",
    "    # Just one painting\n",
    "    else:\n",
    "        # Get Corners\n",
    "        corners = detect_corners(mask)\n",
    "\n",
    "        # Draw polygon\n",
    "        poly = Image.new('RGB', (mask_pred.shape[1], mask_pred.shape[0]), (0))\n",
    "        pdraw = ImageDraw.Draw(poly)\n",
    "        pdraw.polygon(xy=corners, fill=(1), outline=None)\n",
    "        mask_pred_f = np.array(poly)[:, :, 0]\n",
    "        mask_f = mask_pred_f\n",
    "\n",
    "    return mask_pred_f, mask_f\n",
    "\n",
    "\n",
    "def k_means(color_space):\n",
    "    \n",
    "    Z = color_space.reshape((-1))\n",
    "    # convert to np.float32\n",
    "    Z = np.float32(Z)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    ret, label, center = cv2.kmeans(Z, 5, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((gray.shape))\n",
    "\n",
    "    mask = np.zeros(color_space.shape[:2],np.uint8)\n",
    "\n",
    "    for l in range(len(center)):\n",
    "        lab_pos = np.where(res2==center[l])\n",
    "        if any(lab_pos[0]==0) or any(lab_pos[1]==0) or any(lab_pos[0]==color_space.shape[0]-1) or any(lab_pos[1]==color_space.shape[1]-1):\n",
    "            continue\n",
    "        else:\n",
    "            mask[lab_pos[0],lab_pos[1]] = 255\n",
    "    \n",
    "    if np.sum(mask) == 0:\n",
    "        pos = np.where(res2==res2[int(color_space.shape[0]/2),int(color_space.shape[1]/2)])\n",
    "        mask[pos[0],pos[1]] = 255\n",
    "        \n",
    "    return mask\n",
    "\n",
    "\n",
    "def crop(query_im, mask_crop):\n",
    "    # Coordinates of non-black pixels.\n",
    "    coords = np.argwhere(mask_crop)\n",
    "\n",
    "    # Bounding box of non-black pixels.\n",
    "    x0, y0 = coords.min(axis=0)\n",
    "    x1, y1 = coords.max(axis=0) + 1 # slices are exclusive at the top\n",
    "\n",
    "    # Get the contents of the bounding box.\n",
    "    cropped = query_im[x0:x1, y0:y1]\n",
    "    mask_cropped = mask_crop[x0:x1, y0:y1]\n",
    "\n",
    "    return cropped, mask_cropped, x0, y0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING GLOBAL VARIABLES\n",
    "\n",
    "descriptor = 'ORB'\n",
    "\n",
    "if descriptor is 'SIFT':\n",
    "    method = 'FLANN'\n",
    "    resize_factor = 1/4\n",
    "    MIN_MATCHES = 80\n",
    "    \n",
    "elif descriptor is 'ORB':\n",
    "    method = 'BRUTE_FORCE'\n",
    "    resize_factor = 1/4\n",
    "    MIN_MATCHES = 20\n",
    "    \n",
    "elif descriptor is 'SURF':\n",
    "    method = 'FLANN'\n",
    "    resize_factor = 1/4\n",
    "    MIN_MATCHES = 80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BBDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing image...   ./bbdd/bbdd_00278.jpg"
     ]
    }
   ],
   "source": [
    "folder = './bbdd/'\n",
    "kp_bbdd_array = []\n",
    "des_bbdd_array = []\n",
    "\n",
    "for filename in sorted(listdir(folder)):\n",
    "    if(filename != '.DS_Store' and ('jpg' in filename)):\n",
    "        print (\"\\r Processing image...   {}\".format(folder+filename), end=\"\")\n",
    "        img = cv2.imread(folder + filename,0)#0 is the way of getting B&W image\n",
    "        height, width = img.shape[:2]\n",
    "        resize_size = (int(width*resize_factor), int(height*resize_factor))\n",
    "        img_res = cv2.resize(img, resize_size)\n",
    "        kp_bbdd, des_bbdd = findKeypoints(img_res, descriptor)\n",
    "        kp_bbdd_array.append(kp_bbdd)\n",
    "        des_bbdd_array.append(des_bbdd)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QSD1_W4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing image...   ./qsd1_w4_denoise/00001.jpg"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7bc86ac4b299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Predict mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmask_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaterShed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msat_channel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b68e285f7c47>\u001b[0m in \u001b[0;36mwaterShed\u001b[0;34m(query_img, color_space, sat_chan)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mthresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mthresh_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresh_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b68e285f7c47>\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(color_space)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERM_CRITERIA_EPS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERM_CRITERIA_MAX_ITER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKMEANS_RANDOM_CENTERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0mcenter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder = './qsd1_w4_denoise/'\n",
    "kp_query_array = []\n",
    "des_query_array = []\n",
    "numPaintings = []\n",
    "\n",
    "for filename in sorted(listdir(folder)):\n",
    "    if(filename != '.DS_Store' and ('jpg' in filename)):\n",
    "        print (\"\\r Processing image...   {}\".format(folder+filename), end=\"\")\n",
    "        img = cv2.imread(folder + filename) #0 is the way of getting B&W image\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Get saturation and grayscale from query image\n",
    "        sat = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)[:,:,1]\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if ndimage.variance(sat)<ndimage.variance(gray):\n",
    "            color_space = gray\n",
    "            sat_channel=False\n",
    "            \n",
    "        else:\n",
    "            color_space = sat\n",
    "            sat_channel=True\n",
    "            \n",
    "        # Predict mask\n",
    "        mask_pred,mask = waterShed(img, color_space, sat_channel)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(mask_pred)\n",
    "        plt.title(filename)\n",
    "        \n",
    "        # Save masks\n",
    "        path = './masks_qd'\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        cv2.imwrite('masks_qd/'+filename[:-4]+'.png',mask_pred*255)\n",
    "        if len(mask.shape) > 2:\n",
    "            cv2.imwrite('masks_qd/mask_'+filename[:-4]+'_0.png',mask[:,:,0]*255)\n",
    "            cv2.imwrite('masks_qd/mask_'+filename[:-4]+'_1.png',mask[:,:,1]*255)\n",
    "            numPaintings.append([2])\n",
    "        else:\n",
    "            cv2.imwrite('masks_qd/mask_'+filename[:-4]+'_0.png',mask[:,:]*255)\n",
    "            numPaintings.append([1])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect keypoints for cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing image...   ./qsd1_w4_denoise/00029.jpg"
     ]
    }
   ],
   "source": [
    "query2masks = './masks_qd/'\n",
    "query2folder = './qsd1_w4_denoise/'\n",
    "\n",
    "kp_query_array = []\n",
    "des_query_array = []\n",
    "\n",
    "#COMPUTE SIFT FOR THOSE IMAGES WITHOUT BACKGROUND\n",
    "for filename in sorted(listdir(query2folder)):\n",
    "    if (filename != '.DS_Store' and ('jpg' in filename)):\n",
    "        print (\"\\r Processing image...   {}\".format(query2folder+filename), end=\"\")\n",
    "        query_img = cv2.imread(query2folder + filename)\n",
    "\n",
    "        #cropped, mask_cropped, X0, Y0 = crop(query_img,mask)\n",
    "\n",
    "        height, width = query_img.shape[:2]\n",
    "        resize_size = (int(width*resize_factor), int(height*resize_factor))\n",
    "        img_res = cv2.resize(query_img, resize_size)\n",
    "        kp_query, des_query = findKeypoints(img_res, descriptor)\n",
    "        kp_query_array.append(kp_query)\n",
    "        des_query_array.append(des_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2: Find matches based on the descriptors obtained on Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING FUNCTIONS FOR TASK 2\n",
    "\n",
    "def findMatches(kp1, kp2, des1, des2, method, MIN_MATCH_COUNT = 10):\n",
    "    \n",
    "    if method is 'BRUTE_FORCE':\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        good = bf.match(des1, des2)\n",
    "        \n",
    "    elif method is 'FLANN':\n",
    "        FLANN_INDEX_KDTREE = 0\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks = 50)\n",
    "\n",
    "        # BFMatcher with default params\n",
    "        FLANN_INDEX_KDTREE = 1\n",
    "        index_params= dict(algorithm = FLANN_INDEX_KDTREE,\n",
    "                             trees = 5)\n",
    "        search_param = dict(checks=50)\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "        matches = flann.knnMatch(des1,des2, k=2)\n",
    "\n",
    "        # store all the good matches as per Lowe's ratio test.\n",
    "        good = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                good.append(m)\n",
    "    \n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "        matchesMask = mask.ravel()\n",
    "\n",
    "    else:\n",
    "        matchesMask = 0\n",
    "    \n",
    "    numMatches = np.sum(matchesMask)\n",
    "    \n",
    "    return numMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kp_query_array...   0\n",
      "des_query_array...   278\n",
      "kp_query_array...   1\n",
      "des_query_array...   278\n",
      "kp_query_array...   2\n",
      "des_query_array...   278\n",
      "kp_query_array...   3\n",
      "des_query_array...   278\n",
      "kp_query_array...   4\n",
      "des_query_array...   278\n",
      "kp_query_array...   5\n",
      "des_query_array...   278\n",
      "kp_query_array...   6\n",
      "des_query_array...   278\n",
      "kp_query_array...   7\n",
      "des_query_array...   278\n",
      "kp_query_array...   8\n",
      "des_query_array...   278\n",
      "kp_query_array...   9\n",
      "des_query_array...   278\n",
      "kp_query_array...   10\n",
      "des_query_array...   278\n",
      "kp_query_array...   11\n",
      "des_query_array...   278\n",
      "kp_query_array...   12\n",
      "des_query_array...   278\n",
      "kp_query_array...   13\n",
      "des_query_array...   278\n",
      "kp_query_array...   14\n",
      "des_query_array...   278\n",
      "kp_query_array...   15\n",
      "des_query_array...   278\n",
      "kp_query_array...   16\n",
      "des_query_array...   278\n",
      "kp_query_array...   17\n",
      "des_query_array...   278\n",
      "kp_query_array...   18\n",
      "des_query_array...   278\n",
      "kp_query_array...   19\n",
      "des_query_array...   278\n",
      "kp_query_array...   20\n",
      "des_query_array...   201"
     ]
    }
   ],
   "source": [
    "MIN_MATCH_COUNT = 10\n",
    "numMatches_list = []\n",
    "\n",
    "for i in range(len(kp_query_array)):\n",
    "    numMatches_array = []\n",
    "    print (\"\\nkp_query_array...   {}\".format(i))\n",
    "    for j in range(len(kp_bbdd_array)):\n",
    "        if (des_query_array[i] is not None):\n",
    "            print (\"\\rdes_query_array...   {}\".format(j), end=\"\")\n",
    "            numMatches = findMatches(kp_bbdd_array[j], kp_query_array[i], des_bbdd_array[j], \n",
    "                              des_query_array[i], method, MIN_MATCH_COUNT)\n",
    "            numMatches_array.append(numMatches)\n",
    "        else:\n",
    "            numMatches_array.append(0)\n",
    "        \n",
    "    numMatches_list.append(np.asarray(numMatches_array))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './qsd1_w4/'\n",
    "maskfolder = './masks_qd'\n",
    "kp_query_array = []\n",
    "des_query_array = []\n",
    "numPaintings = []\n",
    "\n",
    "for filename in sorted(listdir(folder)):\n",
    "    if (filename != '.DS_Store' and ('jpg' in filename)):\n",
    "        commonName = filename[0:5]\n",
    "        #print(commonName)\n",
    "    if(('mask_'+ commonName + '_1.png') in listdir(maskfolder)):\n",
    "        numPaintings.append([2])\n",
    "    else:\n",
    "        numPaintings.append([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = []\n",
    "K = 10\n",
    "\n",
    "for i in range(len(numMatches_list)):\n",
    "    maxim = np.max(numMatches_list[i])\n",
    "    \n",
    "    if (numPaintings[i] == [2]):\n",
    "        if (maxim != 0):\n",
    "            pos = np.where(numMatches_list[i] == maxim)\n",
    "            non_maxim = np.delete(numMatches_list[i], pos)\n",
    "        else:\n",
    "            non_maxim = numMatches_list[i]\n",
    "        if (maxim > MIN_MATCHES):\n",
    "            imgs_max1 = np.argsort(-numMatches_list[i])[:K]\n",
    "        else:\n",
    "            imgs_max1 = np.argsort(-numMatches_list[i])[:K-1]\n",
    "            imgs_max1 = np.insert(imgs_max1,0,-1)\n",
    "\n",
    "        result.append([imgs_max1.tolist(), imgs_max1.tolist()])\n",
    "    else:\n",
    "        non_maxim = numMatches_list[i]\n",
    "        if (np.max(non_maxim) > MIN_MATCHES):\n",
    "            imgs = np.argsort(-non_maxim)[:K]\n",
    "        else:\n",
    "            imgs = np.argsort(-non_maxim)[:K-1]\n",
    "            imgs = np.insert(imgs,0,-1)\n",
    "            \n",
    "        result.append([imgs.tolist()])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3:  Evaluate the system on QSD1-W4, map@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.333333333333336\n"
     ]
    }
   ],
   "source": [
    "with open('./qsd1_w4/gt_corresps.pkl', 'rb') as fd:\n",
    "    ll = pickle.load(fd)\n",
    "    \n",
    "\n",
    "gt = [[j] if len(j)==1 else [[j[0]],[j[1]]] for j in ll]  \n",
    "mapk = np.mean([metrics.average_precision.mapk(a,p,3) for a,p in zip(gt, result)])\n",
    "print(mapk*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 4: Evaluate best system from previous week on QSD1-W4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texture descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement texture descriptors \n",
    "Descriptors:\n",
    "* Color\n",
    "* HoG\n",
    "* Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorDescriptor(img,level,numberBins):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2Lab)\n",
    "    \n",
    "    #Calculem tamany del block\n",
    "    height, width = img.shape[:2]\n",
    "    block_height = int(height/level)\n",
    "    block_width = int(width/level)\n",
    "    hist_img = np.empty([0,0])\n",
    "    colorx = ('x','y','z')\n",
    "    canal = 0\n",
    "    for i,col in enumerate(colorx): #Bucle per recorrer els canals de cada imatge  \n",
    "        for r in range(level): #Bucle per recorrer els blocs d'una mateixa row\n",
    "            for c in range(level): #Bucle per recorrer els blocs d'una mateixa column\n",
    "                \n",
    "                block = img[r*block_height:r*block_height+block_height, c*block_width:c*block_width+block_width] \n",
    "                hist = cv2.calcHist([block],[i],None,[numberBins],[0,256]) #Calculem histogrames per blocs\n",
    "                hist_t = hist.transpose()      \n",
    "                #print(hist_t.shape)\n",
    "                #print(hist_img.shape)\n",
    "                if (i==0) and (r==0) and (c==0):\n",
    "                    hist_img = hist_t\n",
    "                else:\n",
    "                    hist_img = np.concatenate((hist_img, hist_t), axis = 1)\n",
    "\n",
    "    cv2.normalize(hist_img, hist_img, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
    "    return hist_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HogDescriptor(img):\n",
    "    hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8))\n",
    "    \n",
    "    return hog_image.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test query system using QSD1-W2 using only texture descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING GLOBAL VARIABLES\n",
    "Level = 1\n",
    "numberBins_color = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compute BBDD descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = './bbdd/'\n",
    "histogram_bbdd_matrix_color = []\n",
    "histogram_bbdd_matrix_texture = []\n",
    "\n",
    "for filename in sorted(listdir(folder)):\n",
    "    if(filename != '.DS_Store' and ('jpg' in filename)):\n",
    "        print (\"\\r Processing image...   {}\".format(folder+filename), end=\"\")\n",
    "        img = cv2.imread(folder + filename)\n",
    "        \n",
    "        equ = np.zeros(img.shape[:], np.uint8)\n",
    "        for c in range(3):\n",
    "            equ[:,:,c] = cv2.equalizeHist(img[:,:,c])\n",
    "        \n",
    "        #COLOR\n",
    "        hist_img_color = colorDescriptor(equ,Level,numberBins_color)\n",
    "        histogram_bbdd_matrix_color.append(hist_img_color)\n",
    "\n",
    "        #TEXTURE\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        image_shape = img.shape[:2]\n",
    "        image = cv2.resize(img, (200, 200))\n",
    "        hist_img_texture = HogDescriptor(image)\n",
    "        hist_img_texture = np.array(hist_img_texture).flatten()\n",
    "        histogram_bbdd_matrix_texture.append(hist_img_texture)\n",
    "        \n",
    "histogram_bbdd_matrix_color = np.asarray(histogram_bbdd_matrix_color)\n",
    "histogram_bbdd_matrix_texture = np.asarray(histogram_bbdd_matrix_texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "# Read txt from bbdd_text\n",
    "textfolder = './bbdd_text/'\n",
    "bbdd_text = []\n",
    "for filename in sorted(listdir(textfolder)):\n",
    "    if(filename != '.DS_Store' and ('txt' in filename)):\n",
    "        with codecs.open(textfolder + filename,'r',encoding='latin1') as f:\n",
    "            if  os.stat(textfolder + filename).st_size == 0:\n",
    "                line = ''\n",
    "                bbdd_text.append(line)\n",
    "                #print(filename + line)\n",
    "            else:\n",
    "                for line in f.readlines():\n",
    "                    lim1 = line.find(\"'\",1)\n",
    "                    lim2 = line.find(\"'\",2)\n",
    "                    bbdd_text.append(line[lim1+1:lim2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compute qsd1_w4 descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "histogram_query_matrix_color = []\n",
    "histogram_query_matrix_texture = []\n",
    "query_text = []\n",
    "\n",
    "query2masks = './masks_qt/'\n",
    "query2folder = './qst1_w4_denoise/'\n",
    "\n",
    "result2 = []\n",
    "\n",
    "with open('qst1_w4_text.pkl', 'rb') as fd:\n",
    "    ll = pickle.load(fd)\n",
    "\n",
    "for filename in sorted(listdir(query2masks)):\n",
    "    if (filename != '.DS_Store' and ('png' in filename) and ('mask' in filename)):\n",
    "        print (\"\\r Processing image...   {}\".format(query2masks+filename), end=\"\")\n",
    "        \n",
    "        mask = cv2.imread(query2masks + filename)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        img_num = filename[5:10]\n",
    "        num_paint = int(filename[-5])\n",
    "        \n",
    "        if (num_paint == 0) and (len(result2) != int(img_num)-1):\n",
    "            result2.append([])\n",
    "            \n",
    "        result2[int(img_num)].append([])\n",
    "        \n",
    "        img = cv2.imread(query2folder + img_num + '.jpg')\n",
    "        \n",
    "        cropped, mask_cropped, X0, Y0 = crop(img,mask)\n",
    "        \n",
    "        equ = np.zeros(img.shape[:], np.uint8)\n",
    "        for c in range(3):\n",
    "            equ[:,:,c] = cv2.equalizeHist(img[:,:,c])\n",
    "        \n",
    "        #COLOR\n",
    "        hist_img_color = colorDescriptor(equ,Level,numberBins_color)\n",
    "        histogram_query_matrix_color.append(hist_img_color)\n",
    "\n",
    "        #TEXTURE\n",
    "        img = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n",
    "        image_shape = img.shape[:2]\n",
    "        image = cv2.resize(img, (200, 200))\n",
    "        hist_img_texture = HogDescriptor(image)\n",
    "        hist_img_texture = np.array(hist_img_texture).flatten()\n",
    "        histogram_query_matrix_texture.append(hist_img_texture)\n",
    "        \n",
    "        img = cropped[ll[int(img_num)][num_paint][1]:ll[int(img_num)][num_paint][3],ll[int(img_num)][num_paint][0]:ll[int(img_num)][num_paint][2]]\n",
    "        if img.shape[0]<4:\n",
    "            query_text.append('')\n",
    "        else:\n",
    "            extractedInformation = pytesseract.image_to_string(img)\n",
    "            query_text.append(extractedInformation)\n",
    "        \n",
    "        with open(img_num+'.txt', 'a') as txtf:\n",
    "            if num_paint==0:\n",
    "                txtf.write(extractedInformation)\n",
    "            else:\n",
    "                txtf.write('\\n'+extractedInformation)\n",
    "            txtf.close()\n",
    "        \n",
    "histogram_query_matrix_color = np.asarray(histogram_query_matrix_color)\n",
    "histogram_query_matrix_texture = np.asarray(histogram_query_matrix_texture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE EVALUATION FUNCTIONS\n",
    "\n",
    "def levenshtein(seq1, seq2):\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    #print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n",
    "def computeMatrixRetrieval_all(histogram_bbdd_color, histogram_query_color, histogram_bbdd_tex, histogram_query_tex, bbdd_text, query_text, K=10):\n",
    "    num_paint = histogram_query_color.shape[0]\n",
    "    \n",
    "    dst_color = np.zeros((num_paint, 279))\n",
    "    dst_tex = np.zeros((num_paint, 279))\n",
    "    dst_text = np.zeros((num_paint, 279))\n",
    "    matrix_retrieval = []\n",
    "\n",
    "    for query_image_index_c in range(0,len(histogram_query_color)): \n",
    "        for bbdd_image_index_c in range(0, len(histogram_bbdd_color)):\n",
    "            \n",
    "            dst_color[query_image_index_c,bbdd_image_index_c] = distance.braycurtis(histogram_query_color[query_image_index_c,:], histogram_bbdd_color[bbdd_image_index_c,:])\n",
    "            dst_tex[query_image_index_c,bbdd_image_index_c] = distance.braycurtis(histogram_query_tex[query_image_index_c,:], histogram_bbdd_tex[bbdd_image_index_c,:])\n",
    "    \n",
    "    for query_text_index in range(0,len(query_text)):\n",
    "        for bbdd_text_index in range(0,len(bbdd_text)-1):\n",
    "            dst_text[query_text_index,bbdd_text_index] = levenshtein(query_text[query_text_index], bbdd_text[bbdd_text_index])       \n",
    "       \n",
    "    \n",
    "    for query_image_index in range(0,len(dst_tex)):\n",
    "        matrix_retrieval_color = np.argsort(dst_color[query_image_index,:])[:K]\n",
    "        matrix_retrieval_tex = np.argsort(dst_tex[query_image_index,:])[:K]\n",
    "        \n",
    "        dst_text_idx_sorted = np.argsort(dst_text[query_image_index,:])\n",
    "        dst_text_sorted = dst_text[query_image_index, dst_text_idx_sorted]<5\n",
    "        \n",
    "        matrix_retrieval_text = dst_text_idx_sorted[:np.sum(dst_text_sorted==True)]\n",
    "        \n",
    "        most_possible = [int(i) for i in matrix_retrieval_tex.tolist() if i in matrix_retrieval_text.tolist()]\n",
    "        \n",
    "        if len(most_possible)<K:\n",
    "            \n",
    "            dst = 1*(dst_tex[query_image_index,:])+ 0*(dst_color[query_image_index,:])\n",
    "            dst_idx_sorted = np.argsort(dst)\n",
    "            \n",
    "            not_in_most_possible = [int(i) for i in dst_idx_sorted.tolist() if int(i) not in most_possible][:K-len(most_possible)]\n",
    "            \n",
    "            if (not most_possible) and (dst[not_in_most_possible[0]]>.25):\n",
    "                most_possible = [-1]\n",
    "                \n",
    "            most_possible = most_possible + not_in_most_possible[:K-len(most_possible)]\n",
    "        \n",
    "        matrix_retrieval.append(most_possible[:K])\n",
    "    \n",
    "    return matrix_retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=10\n",
    "matrix_retrieval = computeMatrixRetrieval_all(histogram_bbdd_matrix_color, histogram_query_matrix_color, histogram_bbdd_matrix_texture, histogram_query_matrix_texture, bbdd_text, query_text, K)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(result2)):\n",
    "    for j in range(len(result2[i])):\n",
    "        result2[i][j] = matrix_retrieval[count]\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./qsd1_w4/gt_corresps.pkl', 'rb') as fd:\n",
    "    ll = pickle.load(fd)\n",
    "    \n",
    "\n",
    "gt = [[j] if len(j)==1 else [[j[0]],[j[1]]] for j in ll]  \n",
    "mapk = np.mean([metrics.average_precision.mapk(a,p,3) for a,p in zip(gt, result2)])\n",
    "print(mapk*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
